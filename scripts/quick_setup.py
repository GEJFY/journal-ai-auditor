#!/usr/bin/env python3
"""
JAIA Quick Setup Script

Interactive setup wizard for configuring JAIA development environment.
Supports both Japanese and English prompts.
"""

import os
import sys
import subprocess
from pathlib import Path


# Colors for terminal output
class Colors:
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    END = '\033[0m'
    BOLD = '\033[1m'


def print_header(text: str) -> None:
    """Print a styled header."""
    print(f"\n{Colors.HEADER}{Colors.BOLD}{'=' * 60}{Colors.END}")
    print(f"{Colors.HEADER}{Colors.BOLD}  {text}{Colors.END}")
    print(f"{Colors.HEADER}{Colors.BOLD}{'=' * 60}{Colors.END}\n")


def print_step(step: int, total: int, text: str) -> None:
    """Print a step indicator."""
    print(f"{Colors.CYAN}[{step}/{total}]{Colors.END} {text}")


def print_success(text: str) -> None:
    """Print a success message."""
    print(f"{Colors.GREEN}âœ“ {text}{Colors.END}")


def print_warning(text: str) -> None:
    """Print a warning message."""
    print(f"{Colors.WARNING}âš  {text}{Colors.END}")


def print_error(text: str) -> None:
    """Print an error message."""
    print(f"{Colors.FAIL}âœ— {text}{Colors.END}")


def ask_choice(prompt: str, options: list[str], default: int = 0) -> int:
    """Ask user to choose from options."""
    print(f"\n{prompt}")
    for i, option in enumerate(options):
        marker = ">" if i == default else " "
        print(f"  {marker} [{i + 1}] {option}")

    while True:
        try:
            choice = input(f"\né¸æŠã—ã¦ãã ã•ã„ (1-{len(options)}) [{default + 1}]: ").strip()
            if not choice:
                return default
            idx = int(choice) - 1
            if 0 <= idx < len(options):
                return idx
        except ValueError:
            pass
        print_warning("ç„¡åŠ¹ãªé¸æŠã§ã™ã€‚ã‚‚ã†ä¸€åº¦å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")


def ask_input(prompt: str, default: str = "", secret: bool = False) -> str:
    """Ask user for text input."""
    if default:
        display = f"{prompt} [{default}]: "
    else:
        display = f"{prompt}: "

    if secret:
        import getpass
        value = getpass.getpass(display)
    else:
        value = input(display).strip()

    return value if value else default


def ask_yes_no(prompt: str, default: bool = True) -> bool:
    """Ask user a yes/no question."""
    default_str = "Y/n" if default else "y/N"
    while True:
        answer = input(f"{prompt} [{default_str}]: ").strip().lower()
        if not answer:
            return default
        if answer in ("y", "yes", "ã¯ã„"):
            return True
        if answer in ("n", "no", "ã„ã„ãˆ"):
            return False
        print_warning("y ã¾ãŸã¯ n ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚")


def check_python() -> bool:
    """Check Python version."""
    version = sys.version_info
    if version.major == 3 and version.minor >= 11:
        print_success(f"Python {version.major}.{version.minor}.{version.micro} âœ“")
        return True
    else:
        print_error(f"Python 3.11ä»¥ä¸ŠãŒå¿…è¦ã§ã™ (ç¾åœ¨: {version.major}.{version.minor})")
        return False


def check_node() -> bool:
    """Check Node.js installation."""
    try:
        result = subprocess.run(
            ["node", "--version"],
            capture_output=True,
            text=True
        )
        version = result.stdout.strip()
        major = int(version.lstrip("v").split(".")[0])
        if major >= 18:
            print_success(f"Node.js {version} âœ“")
            return True
        else:
            print_error(f"Node.js 18ä»¥ä¸ŠãŒå¿…è¦ã§ã™ (ç¾åœ¨: {version})")
            return False
    except FileNotFoundError:
        print_error("Node.js ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False


def setup_backend(project_root: Path) -> bool:
    """Set up backend environment."""
    backend_dir = project_root / "backend"
    venv_dir = backend_dir / "venv"

    # Create virtual environment
    if not venv_dir.exists():
        print("ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆä¸­...")
        subprocess.run([sys.executable, "-m", "venv", str(venv_dir)])
        print_success("ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã—ã¾ã—ãŸ")
    else:
        print_success("ä»®æƒ³ç’°å¢ƒã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")

    # Install dependencies
    print("ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...")
    if sys.platform == "win32":
        pip_path = venv_dir / "Scripts" / "pip.exe"
    else:
        pip_path = venv_dir / "bin" / "pip"

    result = subprocess.run(
        [str(pip_path), "install", "-r", str(backend_dir / "requirements.txt")],
        capture_output=True,
        text=True
    )

    if result.returncode == 0:
        print_success("ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã—ãŸ")
        return True
    else:
        print_error("ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•—ã—ã¾ã—ãŸ")
        print(result.stderr)
        return False


def setup_frontend(project_root: Path) -> bool:
    """Set up frontend environment."""
    frontend_dir = project_root / "frontend"

    print("ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...")
    result = subprocess.run(
        ["npm", "install"],
        cwd=str(frontend_dir),
        capture_output=True,
        text=True,
        shell=True
    )

    if result.returncode == 0:
        print_success("ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã—ãŸ")
        return True
    else:
        print_error("npm install ã«å¤±æ•—ã—ã¾ã—ãŸ")
        print(result.stderr)
        return False


def configure_llm(project_root: Path) -> None:
    """Configure LLM provider."""
    print_header("LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®š")

    providers = [
        "Anthropic Claude (æ¨å¥¨)",
        "AWS Bedrock",
        "Google Vertex AI",
        "Azure OpenAI",
        "ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå¾Œã§è¨­å®šï¼‰"
    ]

    choice = ask_choice("ä½¿ç”¨ã™ã‚‹LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„:", providers)

    env_content = {
        "LLM_PROVIDER": "",
        "ANTHROPIC_API_KEY": "",
        "AWS_REGION": "us-east-1",
        "GCP_PROJECT_ID": "",
        "AZURE_OPENAI_ENDPOINT": "",
        "AZURE_OPENAI_API_KEY": "",
    }

    if choice == 0:  # Anthropic
        env_content["LLM_PROVIDER"] = "anthropic"
        api_key = ask_input("Anthropic APIã‚­ãƒ¼ã‚’å…¥åŠ›", secret=True)
        if api_key:
            env_content["ANTHROPIC_API_KEY"] = api_key

    elif choice == 1:  # AWS Bedrock
        env_content["LLM_PROVIDER"] = "bedrock"
        region = ask_input("AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³", default="us-east-1")
        env_content["AWS_REGION"] = region
        print("\næ³¨æ„: AWSèªè¨¼ã«ã¯AWS CLIã®è¨­å®šãŒå¿…è¦ã§ã™")
        print("  aws configure ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

    elif choice == 2:  # Vertex AI
        env_content["LLM_PROVIDER"] = "vertex"
        project_id = ask_input("GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID")
        if project_id:
            env_content["GCP_PROJECT_ID"] = project_id
        print("\næ³¨æ„: GOOGLE_APPLICATION_CREDENTIALS ç’°å¢ƒå¤‰æ•°ã®è¨­å®šãŒå¿…è¦ã§ã™")

    elif choice == 3:  # Azure OpenAI
        env_content["LLM_PROVIDER"] = "azure"
        endpoint = ask_input("Azure OpenAI ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ")
        api_key = ask_input("Azure OpenAI APIã‚­ãƒ¼", secret=True)
        if endpoint:
            env_content["AZURE_OPENAI_ENDPOINT"] = endpoint
        if api_key:
            env_content["AZURE_OPENAI_API_KEY"] = api_key

    else:  # Skip
        env_content["LLM_PROVIDER"] = "anthropic"
        print_warning("LLMè¨­å®šã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚å¾Œã§ backend/.env ã‚’ç·¨é›†ã—ã¦ãã ã•ã„ã€‚")
        return

    # Write .env file
    env_path = project_root / "backend" / ".env"
    env_lines = [
        "# JAIA Backend Configuration",
        "# Generated by quick_setup.py",
        "",
        "# Application",
        "APP_NAME=JAIA",
        "DEBUG=true",
        "ENVIRONMENT=development",
        "",
        "# Server",
        "HOST=127.0.0.1",
        "PORT=8090",
        "",
        "# Database",
        "DATA_DIR=./data",
        "DUCKDB_PATH=./data/jaia.duckdb",
        "SQLITE_PATH=./data/jaia_meta.db",
        "",
        "# LLM Provider",
        f"LLM_PROVIDER={env_content['LLM_PROVIDER']}",
        "",
    ]

    if env_content["ANTHROPIC_API_KEY"]:
        env_lines.append(f"ANTHROPIC_API_KEY={env_content['ANTHROPIC_API_KEY']}")
    if env_content["AWS_REGION"]:
        env_lines.append(f"AWS_REGION={env_content['AWS_REGION']}")
    if env_content["GCP_PROJECT_ID"]:
        env_lines.append(f"GCP_PROJECT_ID={env_content['GCP_PROJECT_ID']}")
    if env_content["AZURE_OPENAI_ENDPOINT"]:
        env_lines.append(f"AZURE_OPENAI_ENDPOINT={env_content['AZURE_OPENAI_ENDPOINT']}")
    if env_content["AZURE_OPENAI_API_KEY"]:
        env_lines.append(f"AZURE_OPENAI_API_KEY={env_content['AZURE_OPENAI_API_KEY']}")

    env_lines.extend([
        "",
        "# Performance",
        "BATCH_SIZE=10000",
        "MAX_WORKERS=4",
        "CACHE_TTL_SECONDS=300",
        "",
        "# Logging",
        "LOG_LEVEL=INFO",
    ])

    with open(env_path, "w", encoding="utf-8") as f:
        f.write("\n".join(env_lines))

    print_success(f".env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: {env_path}")


def configure_frontend(project_root: Path) -> None:
    """Configure frontend environment."""
    env_path = project_root / "frontend" / ".env.local"

    env_content = """# JAIA Frontend Configuration
# Generated by quick_setup.py

# API
VITE_API_BASE=http://localhost:8090/api/v1

# Development
NODE_ENV=development
"""

    with open(env_path, "w", encoding="utf-8") as f:
        f.write(env_content)

    print_success(f"ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¨­å®šã‚’ä½œæˆã—ã¾ã—ãŸ: {env_path}")


def main():
    """Main setup wizard."""
    print_header("JAIA ã‚¯ã‚¤ãƒƒã‚¯ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—")
    print("Journal entry AI Analyzer ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’é–‹å§‹ã—ã¾ã™ã€‚\n")

    # Determine project root
    script_dir = Path(__file__).parent
    project_root = script_dir.parent

    print(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {project_root}\n")

    # Step 1: Check requirements
    print_step(1, 5, "ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ã‚’ç¢ºèªä¸­...")
    python_ok = check_python()
    node_ok = check_node()

    if not python_ok or not node_ok:
        print_error("\nã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“ã€‚ä¸è¶³ã—ã¦ã„ã‚‹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)

    # Step 2: Setup backend
    print_step(2, 5, "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
    if not setup_backend(project_root):
        print_error("\nãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        sys.exit(1)

    # Step 3: Setup frontend
    print_step(3, 5, "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
    if not setup_frontend(project_root):
        print_error("\nãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        sys.exit(1)

    # Step 4: Configure LLM
    print_step(4, 5, "LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’è¨­å®šä¸­...")
    configure_llm(project_root)

    # Step 5: Configure frontend
    print_step(5, 5, "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¨­å®šã‚’ä½œæˆä¸­...")
    configure_frontend(project_root)

    # Create data directory
    data_dir = project_root / "backend" / "data"
    data_dir.mkdir(exist_ok=True)

    # Summary
    print_header("ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")

    print("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"{Colors.CYAN}1.{Colors.END} ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰:")
    print(f"   cd backend && .\\venv\\Scripts\\activate")
    print(f"   python ..\\scripts\\load_sample_data.py")
    print()
    print(f"{Colors.CYAN}2.{Colors.END} ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’èµ·å‹•:")
    print(f"   python -m uvicorn app.main:app --host 127.0.0.1 --port 8090")
    print()
    print(f"{Colors.CYAN}3.{Colors.END} ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚’èµ·å‹•ï¼ˆåˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ï¼‰:")
    print(f"   cd frontend && npm run dev")
    print()
    print(f"{Colors.CYAN}4.{Colors.END} ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚¢ã‚¯ã‚»ã‚¹:")
    print(f"   http://localhost:5290")
    print()
    print(f"{Colors.GREEN}Happy auditing! ğŸ‰{Colors.END}\n")


if __name__ == "__main__":
    main()
