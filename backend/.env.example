# JAIA Backend Configuration Example
# 2026 Cloud Edition - Multi-Provider LLM Support
#
# Copy this file to .env and fill in your API keys:
#   cp .env.example .env
#
# Choose ONE provider and uncomment its settings

# =============================================================================
# Application
# =============================================================================
APP_NAME=JAIA
DEBUG=true
ENVIRONMENT=development

# Server
HOST=127.0.0.1
PORT=8001

# Database
DATA_DIR=./data
DUCKDB_PATH=./data/jaia.duckdb
SQLITE_PATH=./data/jaia_meta.db

# =============================================================================
# LLM Provider Selection (choose one)
# =============================================================================
# Options: bedrock | azure_foundry | vertex_ai | anthropic | openai | google | azure | ollama
#
# Recommended:
#   - Enterprise: bedrock (Claude Opus 4.6)
#   - Latest: azure_foundry (GPT-5.2)
#   - Cost: vertex_ai (Gemini 2.5 Flash Lite)
#   - Local Dev: ollama (Phi-4, DeepSeek R1)

LLM_PROVIDER=bedrock
LLM_MODEL=us.anthropic.claude-opus-4-6-20260201-v1:0

# =============================================================================
# AWS Bedrock (Recommended for Enterprise)
# Models: us.anthropic.claude-opus-4-6-20260201-v1:0  (Precision)
#         us.anthropic.claude-sonnet-4-5-20250929-v1:0
#         us.anthropic.claude-haiku-4-5-20251001-v1:0  (Cost)
#         amazon.nova-premier-v1:0, amazon.nova-pro-v1:0
#         amazon.nova-lite-v1:0, amazon.nova-micro-v1:0
# =============================================================================
# AWS_REGION=us-east-1
# AWS_ACCESS_KEY_ID=AKIA...
# AWS_SECRET_ACCESS_KEY=...

# =============================================================================
# Azure AI Foundry (Latest GPT-5 series + Claude)
# Models: gpt-5.2, gpt-5, gpt-5-nano             (OpenAI)
#         claude-opus-4-6, claude-sonnet-4-5       (Anthropic)
# =============================================================================
# AZURE_FOUNDRY_ENDPOINT=https://your-foundry.openai.azure.com/
# AZURE_FOUNDRY_API_KEY=...
# AZURE_FOUNDRY_DEPLOYMENT=gpt-5-2-deployment
# AZURE_FOUNDRY_API_VERSION=2026-01-01

# =============================================================================
# GCP Vertex AI (Cost Effective)
# Models: gemini-3-pro, gemini-3-flash-preview     (Latest)
#         gemini-2.5-pro, gemini-2.5-flash-lite     (Cost)
# =============================================================================
# GCP_PROJECT_ID=your-project-id
# GCP_LOCATION=us-central1
# GCP_CREDENTIALS_PATH=./credentials/gcp-credentials.json

# =============================================================================
# Anthropic Direct API
# Models: claude-opus-4-6, claude-sonnet-4-5, claude-haiku-4-5
# =============================================================================
# ANTHROPIC_API_KEY=sk-ant-api03-...

# =============================================================================
# OpenAI Direct API
# Models: gpt-5.2, gpt-5, gpt-5-mini, gpt-5-nano  (GPT-5 series)
#         o3-pro, o3, o4-mini                        (Reasoning)
# =============================================================================
# OPENAI_API_KEY=sk-proj-...

# =============================================================================
# Google AI Studio
# Models: gemini-3-flash-preview, gemini-2.5-pro, gemini-2.5-flash-lite
# =============================================================================
# GOOGLE_API_KEY=AIzaSy...

# =============================================================================
# Azure OpenAI (Legacy)
# Models: gpt-4o, gpt-4o-mini
# =============================================================================
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
# AZURE_OPENAI_API_KEY=...
# AZURE_OPENAI_DEPLOYMENT=gpt-4o-deployment
# AZURE_OPENAI_API_VERSION=2024-10-21

# =============================================================================
# Ollama (Local LLM - Development/Testing)
# Install: curl -fsSL https://ollama.ai/install.sh | sh
# Models: phi4 (recommended), deepseek-r1:14b, qwen2.5-coder:14b,
#         llama3.3:8b, gemma3:27b
# =============================================================================
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=phi4

# =============================================================================
# Performance
# =============================================================================
BATCH_SIZE=10000
MAX_WORKERS=4
CACHE_TTL_SECONDS=300

# =============================================================================
# Logging
# =============================================================================
LOG_LEVEL=INFO
