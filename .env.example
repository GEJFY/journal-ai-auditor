# JAIA Environment Configuration
# 2026 Cloud Edition - Multi-Provider LLM Support
#
# Copy to .env and fill in your values:
#   cp .env.example .env

# ============================================
# Application Settings
# ============================================
ENVIRONMENT=development
DEBUG=true

# ============================================
# Server Ports
# ============================================
BACKEND_PORT=8001
FRONTEND_PORT=80
REDIS_PORT=6379

# ============================================
# LLM Provider Selection
# ============================================
# Options: bedrock | azure_foundry | vertex_ai | anthropic | openai | google | azure | ollama
#
# Recommended:
#   - Enterprise: bedrock (Claude Opus 4.6)
#   - Latest: azure_foundry (GPT-5.2)
#   - Cost: vertex_ai (Gemini 2.5 Flash Lite)
#   - Local Dev: ollama (Phi-4, DeepSeek R1)

LLM_PROVIDER=bedrock
LLM_MODEL=us.anthropic.claude-opus-4-6-20260201-v1:0

# ============================================
# AWS Bedrock (Recommended for Enterprise)
# ============================================
# Models:
#   - us.anthropic.claude-opus-4-6-20260201-v1:0 (Precision)
#   - us.anthropic.claude-sonnet-4-5-20250929-v1:0 (Balanced)
#   - us.anthropic.claude-haiku-4-5-20251001-v1:0 (Cost)
#   - amazon.nova-premier-v1:0, amazon.nova-pro-v1:0
#   - amazon.nova-lite-v1:0, amazon.nova-micro-v1:0
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
# AWS_BEDROCK_ENDPOINT=  # Optional custom endpoint

# ============================================
# Azure Foundry (Latest GPT-5 series + Claude)
# ============================================
# Models:
#   - gpt-5.2, gpt-5, gpt-5-nano (OpenAI)
#   - claude-opus-4-6, claude-sonnet-4-5 (Anthropic)
AZURE_FOUNDRY_ENDPOINT=
AZURE_FOUNDRY_API_KEY=
AZURE_FOUNDRY_DEPLOYMENT=
AZURE_FOUNDRY_API_VERSION=2026-01-01

# ============================================
# GCP Vertex AI (Cost Effective - Gemini 3.0)
# ============================================
# Models:
#   - gemini-3-pro, gemini-3-flash-preview (Latest, global only)
#   - gemini-2.5-pro, gemini-2.5-flash-lite (Cost, regional OK)
GCP_PROJECT_ID=
GCP_LOCATION=global
#   Gemini 3.0: "global" のみ対応
#   Gemini 2.5: "us-central1" 等リージョナルも利用可
GCP_CREDENTIALS_PATH=./credentials

# ============================================
# Anthropic Direct API
# ============================================
# Models: claude-opus-4-6, claude-sonnet-4-5, claude-haiku-4-5
ANTHROPIC_API_KEY=

# ============================================
# OpenAI Direct API
# ============================================
# Models: gpt-5.2, gpt-5, gpt-5-mini, gpt-5-nano (GPT-5 series)
#         o3-pro, o3, o4-mini (Reasoning)
OPENAI_API_KEY=

# ============================================
# Google AI Studio
# ============================================
# Models: gemini-3-flash-preview, gemini-2.5-pro, gemini-2.5-flash-lite
GOOGLE_API_KEY=

# ============================================
# Azure OpenAI (Legacy)
# ============================================
# Models: gpt-4o, gpt-4o-mini
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_DEPLOYMENT=
AZURE_OPENAI_API_VERSION=2024-10-21

# ============================================
# Ollama (Local LLM - Development/Testing)
# ============================================
# Install: curl -fsSL https://ollama.ai/install.sh | sh
# Models: phi4 (recommended), deepseek-r1:14b, qwen2.5-coder:14b,
#         llama3.3:8b, gemma3:27b
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=phi4

# ============================================
# Performance Settings
# ============================================
BATCH_SIZE=10000
MAX_WORKERS=4
CACHE_TTL_SECONDS=300

# ============================================
# Logging
# ============================================
LOG_LEVEL=INFO
